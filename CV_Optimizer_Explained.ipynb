{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CV Optimizer & Cover Letter Generator - Code Explanation\n",
        "\n",
        "This notebook explains how the CV Optimizer application code works. Each section is accompanied by detailed explanations to understand how the system functions.\n",
        "\n",
        "## ðŸ“š Notebook Structure\n",
        "\n",
        "1. **Imports and Configuration** - Required libraries\n",
        "2. **PDF Extraction** - How to extract text from PDFs\n",
        "3. **Error Handling** - Parsing OpenAI errors\n",
        "4. **CV Optimization** - The core optimization process\n",
        "5. **Cover Letter Generation** - Creating natural-sounding letters\n",
        "6. **Skills Matching** - Analyzing and comparing skills\n",
        "7. **Flask Application** - API endpoints\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** This notebook is for educational purposes. To run the full application, use python script: `app.py`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Libraries\n",
        "\n",
        "Here are all the libraries needed to run the application:\n",
        "\n",
        "- **LangChain**: Framework for building applications with LLMs\n",
        "- **LangChain OpenAI**: Specific integration for OpenAI\n",
        "- **PyPDF2 / pdfplumber**: Text extraction from PDFs\n",
        "- **Flask**: Web framework for creating the API\n",
        "- **Typing**: For Python type hints (better readability)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main imports\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from typing import Dict, Any, Optional, List\n",
        "import re\n",
        "import json\n",
        "from io import BytesIO\n",
        "\n",
        "# For PDF extraction\n",
        "import PyPDF2\n",
        "import pdfplumber\n",
        "\n",
        "# For Flask (if you want to test endpoints)\n",
        "# from flask import Flask, request, jsonify\n",
        "# from flask_cors import CORS\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. PDF Text Extraction\n",
        "\n",
        "### How it works?\n",
        "\n",
        "PDF extraction uses **two methods** to maximize success chances:\n",
        "\n",
        "1. **pdfplumber** (primary method): Better for complex PDFs with layouts\n",
        "2. **PyPDF2** (fallback method): More basic but more robust\n",
        "\n",
        "### Why two methods?\n",
        "\n",
        "Some PDFs are better read by one method than the other. By using both, we maximize the chances of correctly extracting text, even from poorly formatted PDFs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_file) -> str:\n",
        "    \"\"\"\n",
        "    Extract text from a PDF file using multiple methods for better accuracy.\n",
        "    \n",
        "    Strategy: Try pdfplumber first (better for complex layouts),\n",
        "    then fallback to PyPDF2 if it fails.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    \n",
        "    # Method 1: pdfplumber (better for complex layouts)\n",
        "    try:\n",
        "        # Convert bytes to BytesIO if necessary\n",
        "        if isinstance(pdf_file, bytes):\n",
        "            pdf_file = BytesIO(pdf_file)\n",
        "        \n",
        "        # Open PDF and extract text page by page\n",
        "        with pdfplumber.open(pdf_file) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "        \n",
        "        # If we successfully extracted text, return it\n",
        "        if text.strip():\n",
        "            return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ pdfplumber failed: {e}\")\n",
        "        # Continue with fallback method\n",
        "    \n",
        "    # Method 2: PyPDF2 (fallback)\n",
        "    try:\n",
        "        # Reset file if it was bytes\n",
        "        if isinstance(pdf_file, bytes):\n",
        "            pdf_file = BytesIO(pdf_file)\n",
        "        \n",
        "        # Read PDF with PyPDF2\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ PyPDF2 failed: {e}\")\n",
        "    \n",
        "    # Return extracted text (may be empty if both methods failed)\n",
        "    return text.strip() if text else \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. OpenAI Error Handling\n",
        "\n",
        "### Why is it important?\n",
        "\n",
        "OpenAI API errors are often technical and hard to understand for users. This function **parses errors** and transforms them into clear messages with instructions to solve the problem.\n",
        "\n",
        "### Types of errors handled:\n",
        "\n",
        "- **401**: Invalid API key â†’ Instructions to get a new key\n",
        "- **429**: Rate limit â†’ Informative message\n",
        "- **500**: Server error â†’ Informative message\n",
        "- **Insufficient credits**: Link to billing page\n",
        "- **Invalid model**: Suggestion to choose another model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_openai_error(error: Exception) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Parse OpenAI API errors and return user-friendly messages.\n",
        "    \n",
        "    This function analyzes the error message and identifies the error type\n",
        "    to return a clear and actionable message to the user.\n",
        "    \"\"\"\n",
        "    error_str = str(error)\n",
        "    \n",
        "    # Initialize default values\n",
        "    error_code = None\n",
        "    error_message = error_str\n",
        "    user_message = \"An error occurred when calling the OpenAI API.\"\n",
        "    \n",
        "    # Detect 401 error (Invalid API Key)\n",
        "    if \"401\" in error_str or \"invalid_api_key\" in error_str.lower() or \"Incorrect API key\" in error_str:\n",
        "        error_code = 401\n",
        "        user_message = (\n",
        "            \"Error: Invalid OpenAI API key.\\n\\n\"\n",
        "            \"Your API key is not valid or has expired. Please:\\n\"\n",
        "            \"1. Verify that you copied the complete key\\n\"\n",
        "            \"2. Get a new key at: https://platform.openai.com/account/api-keys\\n\"\n",
        "            \"3. Verify that your OpenAI account has available credits\"\n",
        "        )\n",
        "    \n",
        "    # Detect 429 error (Rate Limit)\n",
        "    elif \"429\" in error_str or \"rate_limit\" in error_str.lower():\n",
        "        error_code = 429\n",
        "        user_message = (\n",
        "            \"Error: Rate limit exceeded.\\n\\n\"\n",
        "            \"You have made too many requests. Please wait a few moments before trying again.\"\n",
        "        )\n",
        "    \n",
        "    # Detect 500 error (Server Error)\n",
        "    elif \"500\" in error_str or \"internal_error\" in error_str.lower():\n",
        "        error_code = 500\n",
        "        user_message = (\n",
        "            \"Error: OpenAI server problem.\\n\\n\"\n",
        "            \"The OpenAI server is experiencing difficulties. Please try again in a few moments.\"\n",
        "        )\n",
        "    \n",
        "    # Detect insufficient credits\n",
        "    elif \"insufficient_quota\" in error_str.lower() or \"billing\" in error_str.lower():\n",
        "        error_code = \"billing\"\n",
        "        user_message = (\n",
        "            \"Error: Insufficient credits.\\n\\n\"\n",
        "            \"Your OpenAI account no longer has available credits. \"\n",
        "            \"Please add credits at: https://platform.openai.com/account/billing\"\n",
        "        )\n",
        "    \n",
        "    # Detect invalid model\n",
        "    elif \"model\" in error_str.lower() and (\"not found\" in error_str.lower() or \"invalid\" in error_str.lower()):\n",
        "        error_code = \"model\"\n",
        "        user_message = (\n",
        "            \"Error: Invalid model.\\n\\n\"\n",
        "            \"The selected model is not available. Please choose another model.\"\n",
        "        )\n",
        "    \n",
        "    return {\n",
        "        \"error_code\": error_code,\n",
        "        \"error_message\": error_message,\n",
        "        \"user_message\": user_message\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. CV Optimization\n",
        "\n",
        "### How it works\n",
        "\n",
        "CV optimization uses **LangChain** to create a processing chain:\n",
        "\n",
        "1. **Create the LLM model**: Configure the OpenAI model (GPT-4o-mini by default)\n",
        "2. **Build the prompt**: Create a system prompt that guides the AI\n",
        "3. **Invoke**: Send the CV and job description to the AI\n",
        "4. **Result**: The AI returns an optimized CV\n",
        "\n",
        "### Important parameters\n",
        "\n",
        "- **Temperature (0.3)**: Low for a deterministic and consistent CV\n",
        "- **Language**: The prompt is adapted according to the chosen language\n",
        "- **Filters**: Min/max number of experiences, max years\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimize_cv(\n",
        "    cv_text: str,\n",
        "    job_description: str,\n",
        "    api_key: str,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "    temperature: float = 0.3,\n",
        "    min_experiences: int = 3,\n",
        "    max_experiences: int = 8,\n",
        "    max_date_years: Optional[int] = None,\n",
        "    language: str = \"fr\",\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Optimize a CV for a specific job description.\n",
        "    \n",
        "    This function uses LangChain to create a processing chain\n",
        "    that optimizes the CV according to the job description.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Step 1: Initialize LangChain model with OpenAI\n",
        "    llm = ChatOpenAI(\n",
        "        model=model,\n",
        "        temperature=temperature,  # Low temperature = more deterministic\n",
        "        api_key=api_key\n",
        "    )\n",
        "    \n",
        "    # Step 2: Build dynamic filtering instructions\n",
        "    date_filter = \"\"\n",
        "    if max_date_years:\n",
        "        date_filter = f\"\\n- Only include experiences from the last {max_date_years} years\"\n",
        "    \n",
        "    exp_filter = f\"\\n- Include between {min_experiences} and {max_experiences} professional experiences\"\n",
        "    \n",
        "    # Step 3: Map language for the prompt\n",
        "    language_names = {\n",
        "        \"fr\": \"French (FranÃ§ais)\",\n",
        "        \"en\": \"English\",\n",
        "        \"es\": \"Spanish (EspaÃ±ol)\"\n",
        "    }\n",
        "    target_language = language_names.get(language, \"French (FranÃ§ais)\")\n",
        "    \n",
        "    # Step 4: Build system message (instructions for AI)\n",
        "    system_message = f\"\"\"You are an expert CV/resume optimizer. Your task is to tailor a candidate's CV to match a specific job description while maintaining authenticity and truthfulness.\n",
        "\n",
        "CRITICAL: The entire CV must be written in {target_language}. All sections, descriptions, and content must be in this language.\n",
        "\n",
        "Guidelines:\n",
        "- Keep all information factual and accurate\n",
        "- Reorganize and rephrase content to highlight relevant skills and experiences\n",
        "- Use action verbs and quantify achievements where possible\n",
        "- Maintain professional formatting with clear sections\n",
        "- Ensure ATS (Applicant Tracking System) compatibility\n",
        "- Keep the same structure: Header, Summary, Experience, Education, Skills, etc.{date_filter}{exp_filter}\n",
        "- Focus on experiences and skills most relevant to the job\n",
        "- Remove or de-emphasize irrelevant information\n",
        "- Use industry-standard terminology from the job description where appropriate\n",
        "- Write everything in {target_language} - section headers, descriptions, and all text\"\"\"\n",
        "    \n",
        "    # Step 5: Create prompt template with LangChain\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_message),  # General instructions\n",
        "        (\"human\", \"\"\"Job Description:\n",
        "{job_description}\n",
        "\n",
        "Original CV:\n",
        "{cv_text}\n",
        "\n",
        "Create an optimized CV tailored to this job description. Maintain all factual information but reorganize and rephrase to maximize relevance and impact.\"\"\")\n",
        "    ])\n",
        "    \n",
        "    # Step 6: Create the chain (prompt â†’ LLM)\n",
        "    chain = prompt | llm\n",
        "    \n",
        "    # Step 7: Execute the chain with data\n",
        "    try:\n",
        "        response = chain.invoke({\n",
        "            \"job_description\": job_description,\n",
        "            \"cv_text\": cv_text\n",
        "        })\n",
        "        \n",
        "        optimized_cv = response.content\n",
        "        \n",
        "        return {\n",
        "            \"optimized_cv\": optimized_cv,\n",
        "            \"model_used\": model,\n",
        "            \"temperature\": temperature,\n",
        "            \"word_count\": len(optimized_cv.split())\n",
        "        }\n",
        "    except Exception as e:\n",
        "        # Handle errors with our parsing function\n",
        "        error_info = parse_openai_error(e)\n",
        "        return {\n",
        "            \"error\": error_info[\"user_message\"],\n",
        "            \"error_code\": error_info[\"error_code\"],\n",
        "            \"error_details\": error_info[\"error_message\"],\n",
        "            \"optimized_cv\": None\n",
        "        }\n",
        "\n",
        "print(\"OK: CV optimization function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Cover Letter Generation\n",
        "\n",
        "### Goal: Avoid AI Detection\n",
        "\n",
        "Unlike CV optimization (which must be factual), cover letters must **sound natural and human**.\n",
        "\n",
        "### Strategies used:\n",
        "\n",
        "1. **Higher temperature (0.7)**: More creativity and variety\n",
        "2. **Anti-AI instructions**: The prompt guides the AI to avoid detectable patterns\n",
        "3. **Language-specific conventions**: Adapted politeness formulas (Madame/Monsieur in French, Dear in English, etc.)\n",
        "4. **Post-generation cleaning**: Removal of phrases that are too \"AI-like\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_cover_letter(\n",
        "    cv_text: str,\n",
        "    optimized_cv: str,\n",
        "    job_description: str,\n",
        "    api_key: str,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "    temperature: float = 0.7,  # Higher than for CV!\n",
        "    target_words: int = 300,\n",
        "    language: str = \"fr\",\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Generate a personalized cover letter that doesn't sound AI-generated.\n",
        "    \n",
        "    Temperature is higher (0.7) to allow more creativity\n",
        "    and avoid repetitive patterns typical of AI.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialize the model\n",
        "    llm = ChatOpenAI(\n",
        "        model=model,\n",
        "        temperature=temperature,  # More creative than for CV\n",
        "        api_key=api_key\n",
        "    )\n",
        "    \n",
        "    # Round word count to nearest 10\n",
        "    target_words = round(target_words / 10) * 10\n",
        "    \n",
        "    # Map language\n",
        "    language_names = {\n",
        "        \"fr\": \"French (FranÃ§ais)\",\n",
        "        \"en\": \"English\",\n",
        "        \"es\": \"Spanish (EspaÃ±ol)\"\n",
        "    }\n",
        "    target_language = language_names.get(language, \"French (FranÃ§ais)\")\n",
        "    \n",
        "    # Language-specific guidelines for letter conventions\n",
        "    language_guidelines = {\n",
        "        \"fr\": \"- Use appropriate French business letter conventions\\n- Use 'Madame, Monsieur' or 'Madame, Monsieur le Directeur' for formal openings\\n- Use 'Cordialement' or 'Bien cordialement' for closings\\n- Avoid anglicisms and use proper French expressions\",\n",
        "        \"en\": \"- Use appropriate English business letter conventions\\n- Use 'Dear [Name]' or 'Dear Hiring Manager' for openings\\n- Use 'Sincerely' or 'Best regards' for closings\\n- Use natural English expressions and idioms\",\n",
        "        \"es\": \"- Use appropriate Spanish business letter conventions\\n- Use 'Estimado/a [Nombre]' or 'A quien corresponda' for openings\\n- Use 'Atentamente' or 'Saludos cordiales' for closings\\n- Use natural Spanish expressions and idioms\"\n",
        "    }\n",
        "    lang_guidelines = language_guidelines.get(language, language_guidelines[\"fr\"])\n",
        "    \n",
        "    # System message with anti-AI detection instructions\n",
        "    system_message = f\"\"\"You are a professional writer helping someone write a cover letter. Your goal is to create a letter that sounds completely natural and human-written, NOT AI-generated.\n",
        "\n",
        "CRITICAL: The entire cover letter must be written in {target_language}. All content, greetings, and closings must be in this language.\n",
        "\n",
        "CRITICAL GUIDELINES TO AVOID AI DETECTION:\n",
        "- Use varied sentence lengths (mix short and long sentences)\n",
        "- Include occasional conversational elements and personal touches\n",
        "- Avoid overly formal or robotic language\n",
        "- Use natural transitions, not formulaic connectors\n",
        "- Include specific details and anecdotes when possible\n",
        "- Vary your vocabulary - don't repeat the same phrases\n",
        "- Write in a warm, professional but authentic tone\n",
        "- Avoid clichÃ©s - be more direct and personal\n",
        "- Use contractions naturally where appropriate (if culturally acceptable in {target_language})\n",
        "- Include minor imperfections that make it feel human (but keep it professional)\n",
        "- Don't overuse exclamation points or excessive enthusiasm\n",
        "- Be specific about why THIS company and THIS role, not generic statements\n",
        "{lang_guidelines}\n",
        "\n",
        "Target length: approximately {target_words} words (Â±20 words is acceptable).\n",
        "\n",
        "Structure:\n",
        "- Opening: Engaging, specific hook (not generic openings)\n",
        "- Body paragraphs: 2-3 paragraphs connecting experience to role\n",
        "- Closing: Professional but warm sign-off appropriate for {target_language}\n",
        "\n",
        "Make it sound like a real person wrote this in {target_language}, not an AI assistant.\"\"\"\n",
        "    \n",
        "    # Create the prompt\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_message),\n",
        "        (\"human\", \"\"\"Job Description:\n",
        "{job_description}\n",
        "\n",
        "Candidate's Original CV:\n",
        "{cv_text}\n",
        "\n",
        "Candidate's Optimized CV (for reference):\n",
        "{optimized_cv}\n",
        "\n",
        "Write a compelling, natural-sounding cover letter in {target_language} that:\n",
        "1. Shows genuine interest in this specific role and company\n",
        "2. Highlights relevant experience from the CV\n",
        "3. Connects the candidate's background to the job requirements\n",
        "4. Sounds completely human-written (no AI patterns)\n",
        "5. Is approximately {target_words} words\n",
        "6. Uses appropriate business letter conventions for {target_language}\n",
        "\n",
        "Make it personal, authentic, and engaging while remaining professional. Write everything in {target_language}.\"\"\")\n",
        "    ])\n",
        "    \n",
        "    # Create and execute the chain\n",
        "    chain = prompt | llm\n",
        "    \n",
        "    try:\n",
        "        response = chain.invoke({\n",
        "            \"job_description\": job_description,\n",
        "            \"cv_text\": cv_text,\n",
        "            \"optimized_cv\": optimized_cv,\n",
        "            \"target_words\": target_words,\n",
        "            \"target_language\": target_language\n",
        "        })\n",
        "        \n",
        "        cover_letter = response.content.strip()\n",
        "        \n",
        "        # Clean obvious AI artifacts\n",
        "        cover_letter = clean_ai_artifacts(cover_letter)\n",
        "        \n",
        "        word_count = len(cover_letter.split())\n",
        "        \n",
        "        return {\n",
        "            \"cover_letter\": cover_letter,\n",
        "            \"word_count\": word_count,\n",
        "            \"target_words\": target_words,\n",
        "            \"model_used\": model,\n",
        "            \"temperature\": temperature\n",
        "        }\n",
        "    except Exception as e:\n",
        "        error_info = parse_openai_error(e)\n",
        "        return {\n",
        "            \"error\": error_info[\"user_message\"],\n",
        "            \"error_code\": error_info[\"error_code\"],\n",
        "            \"error_details\": error_info[\"error_message\"],\n",
        "            \"cover_letter\": None\n",
        "        }\n",
        "\n",
        "\n",
        "def clean_ai_artifacts(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Remove obvious AI-generated patterns from text.\n",
        "    \n",
        "    This function cleans the text to remove phrases\n",
        "    that are too typical of AI generations.\n",
        "    \"\"\"\n",
        "    # Common phrases generated by AI\n",
        "    ai_phrases = [\n",
        "        r\"I am writing to express my (?:sincere |genuine )?interest\",\n",
        "        r\"I am excited to (?:apply|submit my application)\",\n",
        "        r\"Thank you for (?:considering|taking the time)\",\n",
        "        r\"I believe I would be a (?:great|excellent|perfect) fit\",\n",
        "    ]\n",
        "    \n",
        "    # Remove these phrases\n",
        "    for phrase in ai_phrases:\n",
        "        text = re.sub(phrase, \"\", text, flags=re.IGNORECASE)\n",
        "    \n",
        "    # Replace overly formal formulations\n",
        "    text = re.sub(r\"\\bI am confident that\\b\", \"I'm confident\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"\\bI would like to\\b\", \"I'd like to\", text, flags=re.IGNORECASE)\n",
        "    \n",
        "    # Clean up multiple spaces\n",
        "    text = re.sub(r\" +\", \" \", text)\n",
        "    text = re.sub(r\"\\n\\s*\\n\\s*\\n\", \"\\n\\n\", text)\n",
        "    \n",
        "    return text.strip()\n",
        "\n",
        "print(\"OK: Cover letter generation function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Skills Extraction and Matching\n",
        "\n",
        "### Two-step process\n",
        "\n",
        "1. **Extraction**: Uses AI to extract skills from CV and job offer\n",
        "2. **Matching**: Compares skills and identifies:\n",
        "   - Matches (green)\n",
        "   - Missing skills (red)\n",
        "   - Skills only in CV (gray)\n",
        "   - Interesting CV skills (blue) - identified by AI\n",
        "\n",
        "### Why use AI for extraction?\n",
        "\n",
        "Manual extraction would be tedious. AI understands context and can identify:\n",
        "- Technical skills (Python, React, etc.)\n",
        "- Soft skills (leadership, communication, etc.)\n",
        "- Domain expertise (marketing, finance, etc.)\n",
        "- Certifications and languages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_skills(text: str, api_key: str, text_type: str = \"cv\", model: str = \"gpt-4o-mini\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Extract skills from CV or job description using AI.\n",
        "    \n",
        "    The AI analyzes the text and extracts the main skills.\n",
        "    We use a low temperature (0.2) for a deterministic result.\n",
        "    \"\"\"\n",
        "    llm = ChatOpenAI(\n",
        "        model=model,\n",
        "        temperature=0.2,  # Very low for consistent results\n",
        "        api_key=api_key\n",
        "    )\n",
        "    \n",
        "    # Different prompts depending on text type\n",
        "    if text_type == \"cv\":\n",
        "        system_message = \"\"\"You are an expert at analyzing CVs and resumes. Extract the main skills, competencies, and technical abilities from the CV.\n",
        "\n",
        "Return ONLY a JSON array of skills, nothing else. Each skill should be a short, clear term (2-4 words max).\n",
        "Focus on:\n",
        "- Technical skills (programming languages, tools, software)\n",
        "- Soft skills (communication, leadership, etc.)\n",
        "- Domain expertise (marketing, finance, etc.)\n",
        "- Certifications and qualifications\n",
        "- Languages\n",
        "\n",
        "Format: [\"skill1\", \"skill2\", \"skill3\", ...]\"\"\"\n",
        "        \n",
        "        prompt_text = f\"\"\"Extract all the main skills and competencies from this CV:\n",
        "\n",
        "{text}\n",
        "\n",
        "Return a JSON array of skills only, no explanations.\"\"\"\n",
        "    else:\n",
        "        system_message = \"\"\"You are an expert at analyzing job descriptions. Extract the required and preferred skills, competencies, and qualifications from the job description.\n",
        "\n",
        "Return ONLY a JSON array of skills, nothing else. Each skill should be a short, clear term (2-4 words max).\n",
        "Focus on:\n",
        "- Required technical skills\n",
        "- Preferred technical skills\n",
        "- Soft skills mentioned\n",
        "- Domain expertise required\n",
        "- Certifications or qualifications needed\n",
        "- Language requirements\n",
        "\n",
        "Format: [\"skill1\", \"skill2\", \"skill3\", ...]\"\"\"\n",
        "        \n",
        "        prompt_text = f\"\"\"Extract all the required and preferred skills from this job description:\n",
        "\n",
        "{text}\n",
        "\n",
        "Return a JSON array of skills only, no explanations.\"\"\"\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_message),\n",
        "        (\"human\", prompt_text)\n",
        "    ])\n",
        "    \n",
        "    chain = prompt | llm\n",
        "    \n",
        "    try:\n",
        "        response = chain.invoke({})\n",
        "        content = response.content.strip()\n",
        "        \n",
        "        # Clean content (remove markdown if present)\n",
        "        content = re.sub(r'```json\\s*', '', content)\n",
        "        content = re.sub(r'```\\s*', '', content)\n",
        "        content = content.strip()\n",
        "        \n",
        "        # Parse JSON\n",
        "        try:\n",
        "            skills = json.loads(content)\n",
        "            if not isinstance(skills, list):\n",
        "                skills = [skills]\n",
        "        except json.JSONDecodeError:\n",
        "            # Fallback: try to extract array from text\n",
        "            match = re.search(r'\\[(.*?)\\]', content, re.DOTALL)\n",
        "            if match:\n",
        "                array_content = match.group(1)\n",
        "                skills = [s.strip().strip('\"\\'') for s in array_content.split(',')]\n",
        "                skills = [s for s in skills if s]\n",
        "            else:\n",
        "                # Last resort: split by commas\n",
        "                skills = [s.strip().strip('\"\\'') for s in content.replace('\\n', ',').split(',')]\n",
        "                skills = [s for s in skills if s and len(s) > 1]\n",
        "        \n",
        "        # Clean and normalize\n",
        "        skills = [skill.strip() for skill in skills if skill and len(skill.strip()) > 1]\n",
        "        skills = list(set(skills))  # Remove duplicates\n",
        "        skills = sorted(skills)  # Sort alphabetically\n",
        "        \n",
        "        return {\n",
        "            \"skills\": skills,\n",
        "            \"count\": len(skills),\n",
        "            \"text_type\": text_type\n",
        "        }\n",
        "    except Exception as e:\n",
        "        error_info = parse_openai_error(e)\n",
        "        return {\n",
        "            \"error\": error_info[\"user_message\"],\n",
        "            \"error_code\": error_info[\"error_code\"],\n",
        "            \"skills\": [],\n",
        "            \"count\": 0\n",
        "        }\n",
        "\n",
        "print(\"OK: Skills extraction function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Skills Matching\n",
        "\n",
        "Matching compares skill lists and categorizes them:\n",
        "\n",
        "1. **Exact/partial matches**: Skills present in both\n",
        "2. **CV only**: Skills from CV not mentioned in the offer\n",
        "3. **Offer only**: Required skills missing from CV\n",
        "4. **Interesting**: CV skills that AI deems useful for the position (even if not mentioned)\n",
        "\n",
        "The \"interesting\" part uses AI to analyze context and identify skills that add value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def match_skills(cv_skills: List[str], job_skills: List[str], cv_text: str = \"\", job_text: str = \"\", api_key: str = \"\", model: str = \"gpt-4o-mini\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Match skills between CV and job description.\n",
        "    \n",
        "    This function compares skills and uses AI to identify\n",
        "    which CV skills are \"interesting\" for the position.\n",
        "    \"\"\"\n",
        "    # Normalize skills for comparison (lowercase, no spaces)\n",
        "    cv_normalized = {skill.lower().strip(): skill for skill in cv_skills}\n",
        "    job_normalized = {skill.lower().strip(): skill for skill in job_skills}\n",
        "    \n",
        "    # Find matches\n",
        "    matched = []\n",
        "    cv_only = []\n",
        "    job_only = []\n",
        "    \n",
        "    # Check for matches (exact or partial)\n",
        "    for cv_key, cv_original in cv_normalized.items():\n",
        "        found_match = False\n",
        "        for job_key, job_original in job_normalized.items():\n",
        "            # Exact match\n",
        "            if cv_key == job_key:\n",
        "                matched.append({\n",
        "                    \"cv_skill\": cv_original,\n",
        "                    \"job_skill\": job_original,\n",
        "                    \"match_type\": \"exact\"\n",
        "                })\n",
        "                found_match = True\n",
        "                break\n",
        "            # Partial match (one contains the other)\n",
        "            elif cv_key in job_key or job_key in cv_key:\n",
        "                matched.append({\n",
        "                    \"cv_skill\": cv_original,\n",
        "                    \"job_skill\": job_original,\n",
        "                    \"match_type\": \"partial\"\n",
        "                })\n",
        "                found_match = True\n",
        "                break\n",
        "        \n",
        "        if not found_match:\n",
        "            cv_only.append(cv_original)\n",
        "    \n",
        "    # Find job skills not in CV\n",
        "    for job_key, job_original in job_normalized.items():\n",
        "        found_in_cv = False\n",
        "        for cv_key in cv_normalized.keys():\n",
        "            if cv_key == job_key or cv_key in job_key or job_key in cv_key:\n",
        "                found_in_cv = True\n",
        "                break\n",
        "        if not found_in_cv:\n",
        "            job_only.append(job_original)\n",
        "    \n",
        "    # Identify \"interesting\" skills with AI\n",
        "    interesting = []\n",
        "    if cv_only and api_key and cv_text and job_text:\n",
        "        try:\n",
        "            llm = ChatOpenAI(\n",
        "                model=model,\n",
        "                temperature=0.3,\n",
        "                api_key=api_key\n",
        "            )\n",
        "            \n",
        "            # Prompt to identify interesting skills\n",
        "            prompt_text = f\"\"\"Analyze which CV skills from the list below would be valuable or interesting for this job, even though they are not explicitly mentioned in the job description.\n",
        "\n",
        "Job Description (excerpt):\n",
        "{job_text[:1000]}\n",
        "\n",
        "CV Skills that are NOT in the job description:\n",
        "{', '.join(cv_only[:20])}\n",
        "\n",
        "Return ONLY a JSON array of skills from the list above that would be valuable for this job. Return an empty array [] if none are relevant.\n",
        "\n",
        "Format: [\"skill1\", \"skill2\", ...]\"\"\"\n",
        "            \n",
        "            prompt = ChatPromptTemplate.from_messages([\n",
        "                (\"system\", \"You are an expert at matching candidate skills to job requirements. Identify skills that would add value even if not explicitly required.\"),\n",
        "                (\"human\", prompt_text)\n",
        "            ])\n",
        "            \n",
        "            chain = prompt | llm\n",
        "            response = chain.invoke({})\n",
        "            content = response.content.strip()\n",
        "            \n",
        "            # Parse response\n",
        "            content = re.sub(r'```json\\s*', '', content)\n",
        "            content = re.sub(r'```\\s*', '', content)\n",
        "            content = content.strip()\n",
        "            \n",
        "            try:\n",
        "                interesting_parsed = json.loads(content)\n",
        "                if isinstance(interesting_parsed, list):\n",
        "                    # Match with original skills\n",
        "                    interesting_normalized = [s.lower().strip() for s in interesting_parsed]\n",
        "                    for skill in cv_only:\n",
        "                        if skill.lower().strip() in interesting_normalized:\n",
        "                            interesting.append(skill)\n",
        "            except json.JSONDecodeError:\n",
        "                # Fallback: all CV-only skills\n",
        "                interesting = cv_only.copy()\n",
        "        except Exception:\n",
        "            # If AI analysis fails, use all CV-only skills\n",
        "            interesting = cv_only.copy()\n",
        "    else:\n",
        "        # If no API key, consider all CV-only skills as interesting\n",
        "        interesting = cv_only.copy()\n",
        "    \n",
        "    return {\n",
        "        \"matched\": [m[\"cv_skill\"] for m in matched],  # Green: in both\n",
        "        \"cv_only\": [s for s in cv_only if s not in interesting],  # Gray: CV only\n",
        "        \"job_only\": job_only,  # Red: missing\n",
        "        \"interesting\": interesting,  # Blue: interesting\n",
        "        \"stats\": {\n",
        "            \"total_cv\": len(cv_skills),\n",
        "            \"total_job\": len(job_skills),\n",
        "            \"matched_count\": len(matched),\n",
        "            \"missing_count\": len(job_only),\n",
        "            \"cv_only_count\": len([s for s in cv_only if s not in interesting]),\n",
        "            \"interesting_count\": len(interesting),\n",
        "            \"match_percentage\": round((len(matched) / len(job_skills) * 100) if job_skills else 0, 1)\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(\"OK: Skills matching function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Flask Application - API Endpoints\n",
        "\n",
        "### Flask Architecture\n",
        "\n",
        "Flask creates a web application with several **routes** (endpoints):\n",
        "\n",
        "- `GET /` : Displays the main page\n",
        "- `POST /api/parse-pdf` : Parses a PDF/TXT file\n",
        "- `POST /api/extract-skills` : Extracts skills\n",
        "- `POST /api/match-skills` : Matches skills\n",
        "- `POST /api/optimize-cv` : Optimizes CV\n",
        "- `POST /api/generate-letter` : Generates letter\n",
        "\n",
        "### Data Flow\n",
        "\n",
        "```\n",
        "Frontend (JavaScript) \n",
        "    â†“ (HTTP POST request)\n",
        "Flask Route Handler\n",
        "    â†“ (calls function)\n",
        "Utility module (cv_optimizer, etc.)\n",
        "    â†“ (calls OpenAI)\n",
        "OpenAI API\n",
        "    â†“ (returns result)\n",
        "Utility module\n",
        "    â†“ (returns dict)\n",
        "Flask Route Handler\n",
        "    â†“ (jsonify)\n",
        "Frontend (receives JSON)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example Flask structure (commented code for notebook)\n",
        "# To run the full application, use app.py\n",
        "\n",
        "\"\"\"\n",
        "from flask import Flask, render_template, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Allows cross-origin requests from frontend\n",
        "\n",
        "# Configuration\n",
        "UPLOAD_FOLDER = 'uploads'\n",
        "MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB\n",
        "ALLOWED_EXTENSIONS = {'pdf', 'txt'}\n",
        "\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "\n",
        "# Main route - Displays HTML page\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "# API route - Parse PDF\n",
        "@app.route('/api/parse-pdf', methods=['POST'])\n",
        "def api_parse_pdf():\n",
        "    # 1. Check that a file was sent\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({'error': 'No file provided'}), 400\n",
        "    \n",
        "    file = request.files['file']\n",
        "    \n",
        "    # 2. Check file type\n",
        "    if not allowed_file(file.filename):\n",
        "        return jsonify({'error': 'Invalid file type'}), 400\n",
        "    \n",
        "    # 3. Read content\n",
        "    file_content = file.read()\n",
        "    \n",
        "    # 4. Extract text\n",
        "    if file.filename.endswith('.pdf'):\n",
        "        text = extract_text_from_pdf(file_content)\n",
        "    else:\n",
        "        text = file_content.decode('utf-8')\n",
        "    \n",
        "    # 5. Return result as JSON\n",
        "    return jsonify({\n",
        "        'text': text,\n",
        "        'filename': file.filename,\n",
        "        'word_count': len(text.split())\n",
        "    })\n",
        "\n",
        "# API route - Optimize CV\n",
        "@app.route('/api/optimize-cv', methods=['POST'])\n",
        "def api_optimize_cv():\n",
        "    # 1. Get JSON data\n",
        "    data = request.json\n",
        "    \n",
        "    # 2. Extract parameters\n",
        "    cv_text = data.get('cv_text', '')\n",
        "    job_description = data.get('job_description', '')\n",
        "    api_key = data.get('api_key', '')\n",
        "    # ... other parameters\n",
        "    \n",
        "    # 3. Validate data\n",
        "    if not api_key:\n",
        "        return jsonify({'error': 'API key is required'}), 400\n",
        "    \n",
        "    # 4. Call optimization function\n",
        "    result = optimize_cv(\n",
        "        cv_text=cv_text,\n",
        "        job_description=job_description,\n",
        "        api_key=api_key,\n",
        "        # ... other parameters\n",
        "    )\n",
        "    \n",
        "    # 5. Handle errors\n",
        "    if 'error' in result:\n",
        "        return jsonify({'error': result['error']}), 500\n",
        "    \n",
        "    # 6. Return result\n",
        "    return jsonify(result)\n",
        "\n",
        "# Run application\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, host='127.0.0.1', port=5000)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Usage Examples\n",
        "\n",
        "Here's how to use the functions in the code:\n",
        "\n",
        "### Example 1: Optimize a CV\n",
        "\n",
        "```python\n",
        "# Input data\n",
        "cv_text = \"Your CV text...\"\n",
        "job_description = \"Job description...\"\n",
        "api_key = \"sk-...\"\n",
        "\n",
        "# Call function\n",
        "result = optimize_cv(\n",
        "    cv_text=cv_text,\n",
        "    job_description=job_description,\n",
        "    api_key=api_key,\n",
        "    language=\"fr\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "# Check result\n",
        "if 'error' in result:\n",
        "    print(f\"Error: {result['error']}\")\n",
        "else:\n",
        "    print(f\"Optimized CV ({result['word_count']} words)\")\n",
        "    print(result['optimized_cv'])\n",
        "```\n",
        "\n",
        "### Example 2: Extract and Match Skills\n",
        "\n",
        "```python\n",
        "# Extract skills from CV\n",
        "cv_skills_result = extract_skills(cv_text, api_key, \"cv\")\n",
        "cv_skills = cv_skills_result['skills']\n",
        "\n",
        "# Extract skills from job offer\n",
        "job_skills_result = extract_skills(job_description, api_key, \"job\")\n",
        "job_skills = job_skills_result['skills']\n",
        "\n",
        "# Match skills\n",
        "match_result = match_skills(\n",
        "    cv_skills=cv_skills,\n",
        "    job_skills=job_skills,\n",
        "    cv_text=cv_text,\n",
        "    job_text=job_description,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Display statistics\n",
        "stats = match_result['stats']\n",
        "print(f\"Match: {stats['match_percentage']}%\")\n",
        "print(f\"Matched skills: {len(match_result['matched'])}\")\n",
        "print(f\"Missing skills: {len(match_result['job_only'])}\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Key Takeaways\n",
        "\n",
        "### ðŸ”‘ Important Concepts\n",
        "\n",
        "1. **LangChain**: Framework that simplifies LLM usage\n",
        "   - `ChatOpenAI`: Wrapper for OpenAI\n",
        "   - `ChatPromptTemplate`: Structures prompts\n",
        "   - `chain = prompt | llm`: Creates a processing chain\n",
        "\n",
        "2. **Temperature**:\n",
        "   - **Low (0.2-0.3)**: Deterministic, consistent results â†’ Ideal for CVs\n",
        "   - **High (0.7-1.0)**: More creative, varied â†’ Ideal for letters\n",
        "\n",
        "3. **Error handling**: Always parse OpenAI errors for clear messages\n",
        "\n",
        "4. **PDF extraction**: Dual method (pdfplumber + PyPDF2) for robustness\n",
        "\n",
        "5. **Intelligent matching**: Uses AI to identify \"interesting\" skills\n",
        "\n",
        "### ðŸŽ¯ Best Practices\n",
        "\n",
        "- âœ… Always validate inputs before calling the API\n",
        "- âœ… Handle errors with clear user messages\n",
        "- âœ… Use appropriate temperatures according to use case\n",
        "- âœ… Normalize data before comparison (lowercase, strip)\n",
        "- âœ… Clean AI responses (markdown, JSON parsing)\n",
        "\n",
        "---\n",
        "\n",
        "**To run the full application:**\n",
        "```bash\n",
        "python app.py\n",
        "```\n",
        "\n",
        "**Then open:** `http://127.0.0.1:5000`\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
